{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Unified Bug.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qBEsVEQ0FKqY"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_hGrKUcCakL"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "np.random.seed(42)\n",
        "# metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# preprocessing\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# model selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# models\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# ensembles \n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import IsolationForest"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBEsVEQ0FKqY"
      },
      "source": [
        "##### Only for colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "D9W-EasrEp1g",
        "outputId": "62493f8f-9319-40d4-ddc3-6bbebda0eca3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "elite555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e5b0420cd036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed: invalid oauth code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m       raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed: invalid oauth code"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_nVfbN7Ep1h"
      },
      "source": [
        "# copy data file to current directory\n",
        "!cp /gdrive/MyDrive/data/Unified-class.csv ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBCD2t9eFOkT"
      },
      "source": [
        "### Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrSqbHoCCakN"
      },
      "source": [
        "# getting the data\n",
        "df = pd.read_csv('Unified-class.csv');\n",
        "df.columns = [x.lower() for x in df.columns] # lowercase the columns\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be-m4sBxEhJU"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUUUqAiOYJhp"
      },
      "source": [
        "**The features has no missing values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zVaJNWxFfr9"
      },
      "source": [
        "# getting the number of unique values per 'object' features\n",
        "for col in df.columns:\n",
        "  if df[col].dtype == 'O':\n",
        "    print(col, \": \", df[col].nunique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R4hmpSwYboT"
      },
      "source": [
        "**We will drop all the 'object' features except the `type` feature as they have a huge number of unique values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMJtTFHXHPgW"
      },
      "source": [
        "# drop object features except type \n",
        "df.drop(np.r_[['id'], df.columns[2:7]], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qodSwCk5CakQ"
      },
      "source": [
        "# max and min values in the target class\n",
        "df['bug'].unique().max(), df['bug'].unique().min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jbZtqGAY29V"
      },
      "source": [
        "**The max target value is 62 and the min target value is 0**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vFMSa0eekDx"
      },
      "source": [
        "#### One-hot-encoding the `type` feature "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oibgkE0UHub_"
      },
      "source": [
        "df['type'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqiCx2u-Ifs6"
      },
      "source": [
        "# one-hot-encoding the type feature\n",
        "type_dummies = pd.get_dummies(df['type'])\n",
        "df = pd.concat([df, type_dummies], axis=1)\n",
        "df.drop('type', axis=1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtpUtpYmLCjP"
      },
      "source": [
        "# Splitting the dataframe into features and target\n",
        "columns = list(df.columns)\n",
        "columns.remove('bug')\n",
        "x,y = df[columns] , df['bug']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blZXe3SWM4lV"
      },
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "(x_train.shape, y_train.shape), (x_valid.shape, y_valid.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziNvQJmHO3zZ"
      },
      "source": [
        "# calculates the rmse between the predictions and actual values\n",
        "def rmse_score(y_pred, y):\n",
        "    return np.sqrt(mean_squared_error(y_pred, y))\n",
        "\n",
        "# gets the predictions using x and the estimator and then calculates rmse between the predictions and y\n",
        "def rmse_scorer(estimator, x, y):\n",
        "    y_pred = estimator.predict(x)\n",
        "    return rmse_score(y_pred,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXKdks5oOPr9"
      },
      "source": [
        "# fit_model\n",
        "# takes a model and datasets as input and outputs the scores\n",
        "def fit_model(model, x_train, y_train, x_valid, y_valid):\n",
        "  # fitting the model\n",
        "  model.fit(x_train, y_train)\n",
        "  \n",
        "  # making prediction on the valid data\n",
        "  preds = model.predict(x_valid)\n",
        "  # calculating the scores\n",
        "  rmse_train = rmse_score(y_train, model.predict(x_train))\n",
        "  mse = mean_squared_error(y_valid, preds)\n",
        "  rmse = rmse_score(y_valid, preds)\n",
        "  r2 = r2_score(y_valid, preds) \n",
        "\n",
        "  print(f\"Train RMSE: {rmse_train:.3f} | RMSE: {rmse:.3f}\\n\\\n",
        "          MSE       : {mse:.3f} | \\tR2  : {r2:.3f}\")\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC_KFqoDNflX"
      },
      "source": [
        "# pipeline to scale and then train a random forest\n",
        "pipeline = Pipeline([\n",
        "  ('scaler', StandardScaler()),\n",
        "  ('rf', RandomForestRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "pipeline = fit_model(pipeline, x_train, y_train, x_valid, y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc0XtbH4gp9n"
      },
      "source": [
        "### Outlier Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Mtw0RvjXfGu"
      },
      "source": [
        "# taking a copy of the dataframe\n",
        "no_outliers_df = df.copy()\n",
        "x,y = no_outliers_df[columns] , no_outliers_df['bug']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnUDlImsKhwc"
      },
      "source": [
        "# detecting outliers using IsolationForest\n",
        "outlierDetector =  IsolationForest(n_estimators=100,random_state = 42)\n",
        "result = outlierDetector.fit_predict(x)\n",
        "outliers = no_outliers_df[result==-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3JoqukMVMdx"
      },
      "source": [
        "# drop outliers\n",
        "no_outliers_df = no_outliers_df.drop(outliers.index)\n",
        "print(f'Number of removed outliers {outliers.index.shape[0]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fILRmZwWWPS7"
      },
      "source": [
        "# splitting the new data into train and validation\n",
        "x,y = no_outliers_df[columns] , no_outliers_df['bug']\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "(x_train.shape, y_train.shape), (x_valid.shape, y_valid.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzmI0hqeWogv"
      },
      "source": [
        "# refitting the pipeline after removing the outliers\n",
        "pipeline = fit_model(pipeline, x_train, y_train, x_valid, y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu9E5ZmmZhgo"
      },
      "source": [
        "# correlation \n",
        "corr = pd.DataFrame(no_outliers_df.corr()['bug'].sort_values(ascending=False)[1:])\n",
        "\n",
        "labels = corr.index\n",
        "corr_values = corr['bug'].tolist()\n",
        "\n",
        "plt.figure(figsize=(25, 10))\n",
        "plt.bar(labels, corr_values)\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Correlation with class')\n",
        "plt.title('The Correlation between the Features and Target Column Class')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDoGzS9DaPK8"
      },
      "source": [
        "# helper functions for RandomForests\n",
        "# puts the feature importance of RandomForest in a DataFrame\n",
        "def rf_feat_importance(m, df):\n",
        "    return pd.DataFrame({'cols':df.columns[:-1], 'imp':m.feature_importances_}\n",
        "                       ).sort_values('imp', ascending=False)\n",
        "\n",
        "# Plots the feature importance using the DataFrame\n",
        "def plot_fi(fi, figsize=(12, 7)):\n",
        "    return fi.plot('cols', 'imp', 'barh', figsize=figsize, legend=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsUBgG1NafZk"
      },
      "source": [
        "# Find the features importance \n",
        "fi = rf_feat_importance(pipeline['rf'], no_outliers_df)\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-RCg7CobXVs"
      },
      "source": [
        "# Plot the features importance \r\n",
        "plot_fi(fi, figsize=(15, 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxj-2RvucQZP"
      },
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjED57Zbbf2F"
      },
      "source": [
        "# Printing the \r\n",
        "print(f'Number of features before PCA: {no_outliers_df.shape[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StGEZWuRcptN"
      },
      "source": [
        "pipeline = Pipeline([\n",
        "  ('scaler', StandardScaler()),\n",
        "  ('pca', PCA(n_components=.95, whiten=True, random_state=42)),\n",
        "  ('rf', RandomForestRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "pipeline = fit_model(pipeline, x_train, y_train, x_valid, y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tV9mn9mffWB"
      },
      "source": [
        "pipeline['pca'].n_components_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KmNFDsGd6kv"
      },
      "source": [
        "pipeline = Pipeline([\n",
        "  ('scaler', StandardScaler()),\n",
        "  ('pca', PCA(n_components=.97, whiten=True)),\n",
        "  ('rf', RandomForestRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "pipeline = fit_model(pipeline, x_train, y_train, x_valid, y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PiDAWrLgDAG"
      },
      "source": [
        "pipeline['pca'].n_components_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "003VPVG4iO26"
      },
      "source": [
        "### Training individual models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FjerbUDiNvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91ff98de-ee47-4b59-d707-c78c546f24ec"
      },
      "source": [
        "# RF\n",
        "n_estimators = [int(x) for x in np.linspace(start=10, stop=100, num=10)]\n",
        "\n",
        "max_features = ['auto', 'sqrt']\n",
        "\n",
        "max_depth = [int(x) for x in np.linspace(1, 10, num = 10)]\n",
        "max_depth.append(None)\n",
        "\n",
        "min_samples_split = [2, 5, 10]\n",
        "\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "\n",
        "bootstrap = [True, False]\n",
        "\n",
        "param_grid = {'rf__n_estimators': n_estimators,\n",
        "               'rf__max_features': max_features,\n",
        "               'rf__max_depth': max_depth,\n",
        "               'rf__min_samples_split': min_samples_split,\n",
        "               'rf__min_samples_leaf': min_samples_leaf,\n",
        "               'rf__bootstrap': bootstrap}\n",
        "\n",
        "rf_pipeline = Pipeline([\n",
        "  ('scaler', StandardScaler()),\n",
        "  ('pca', PCA(n_components=.95, whiten=True, random_state=42)),\n",
        "  ('random_rf', RandomizedSearchCV(estimator = RandomForestRegressor(random_state=42), param_distributions = param_grid, \n",
        "                n_iter = 50, cv = 3, verbose=2, random_state=42, n_jobs = -1))\n",
        "])\n",
        "\n",
        "rf_pipeline.fit(x_train, y_train)"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  9.6min\n",
            "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 23.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=Pipeline(memory=None,\n",
              "                                      steps=[('scaler',\n",
              "                                              StandardScaler(copy=True,\n",
              "                                                             with_mean=True,\n",
              "                                                             with_std=True)),\n",
              "                                             ('pca',\n",
              "                                              PCA(copy=True,\n",
              "                                                  iterated_power='auto',\n",
              "                                                  n_components=0.95,\n",
              "                                                  random_state=None,\n",
              "                                                  svd_solver='auto', tol=0.0,\n",
              "                                                  whiten=True)),\n",
              "                                             ('rf',\n",
              "                                              RandomForestRegressor(bootstrap=True,\n",
              "                                                                    ccp_alpha=0.0,\n",
              "                                                                    criterion='mse',\n",
              "                                                                    max_depth=None...\n",
              "                   iid='deprecated', n_iter=50, n_jobs=-1,\n",
              "                   param_distributions={'rf__bootstrap': [True, False],\n",
              "                                        'rf__max_depth': [1, 2, 3, 4, 5, 6, 7,\n",
              "                                                          8, 9, 10, None],\n",
              "                                        'rf__max_features': ['auto', 'sqrt'],\n",
              "                                        'rf__min_samples_leaf': [1, 2, 4],\n",
              "                                        'rf__min_samples_split': [2, 5, 10],\n",
              "                                        'rf__n_estimators': [10, 20, 30, 40, 50,\n",
              "                                                             60, 70, 80, 90,\n",
              "                                                             100]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDKyeJBH0r6B",
        "outputId": "47b0ed8d-0783-4f42-d137-47813e86d913"
      },
      "source": [
        "rf_pipeline.best_params_"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rf__bootstrap': False,\n",
              " 'rf__max_depth': 9,\n",
              " 'rf__max_features': 'sqrt',\n",
              " 'rf__min_samples_leaf': 4,\n",
              " 'rf__min_samples_split': 5,\n",
              " 'rf__n_estimators': 50}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAprvabb0888",
        "outputId": "7bf72f84-4dc8-4e2a-89fc-a8def9c77dd6"
      },
      "source": [
        "rf_pipeline.score(x_valid, y_valid)"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12049582709151774"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXyeauIS1TYJ",
        "outputId": "22b30b75-a5b9-465b-981b-d6467e4e726f"
      },
      "source": [
        "preds = rf_pipeline.predict(x_valid)\n",
        "rmse_score(y_valid, preds)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8413149301315216"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AIXMzHgvCWV",
        "outputId": "9734e917-a00c-4a36-ac08-7cae818c2d17"
      },
      "source": [
        "param_grid = {'C': np.arange(1, 11), 'gamma': [1,0.1,0.01,0.001],'kernel': ['poly', 'linear', 'sigmoid']}\n",
        "\n",
        "rf_pipeline = Pipeline([\n",
        "  ('scaler', StandardScaler()),\n",
        "  ('pca', PCA(n_components=.95, whiten=True)),\n",
        "  ('random_svr', RandomizedSearchCV(estimator = SVR(), param_distributions = param_grid, \n",
        "                               n_iter = 50, cv = 3, verbose=2, random_state=42, n_jobs = -1))\n",
        "])\n",
        "\n",
        "\n",
        "rf_pipeline.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXTPXYztv0s6"
      },
      "source": [
        "param_grid = {'n_neighbors':[4,5,6,7],\n",
        "              'leaf_size':[1,3,5],\n",
        "              'algorithm':['auto', 'kd_tree']}\n",
        "\n",
        "knn_pipeline = Pipeline([\n",
        "  ('scaler', StandardScaler()),\n",
        "  ('pca', PCA(n_components=.95, whiten=True)),\n",
        "  ('random_knn', RandomizedSearchCV(estimator = KNeighborsRegressor(random_state=42), param_distributions = param_grid, \n",
        "                               n_iter = 50, cv = 3, verbose=2, random_state=42, n_jobs = -1))\n",
        "])\n",
        "\n",
        "\n",
        "knn_pipeline.fit(x_train, y_train)\n",
        "knn_pipeline.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}